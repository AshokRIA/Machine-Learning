{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d165384d",
   "metadata": {},
   "source": [
    "# Machine Learning — Regression Assignment (2nd ml)\n",
    "\n",
    "**ashok:** _kumar_\n",
    "\n",
    "---\n",
    "\n",
    "**Contents**\n",
    "\n",
    "1. Questions 1–8: Concepts (Markdown)\n",
    "2. Question 9: Executed linear regression example (code + output)\n",
    "3. Question 10: Interpretation (Markdown)\n",
    "4. How to run / Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035e0fe",
   "metadata": {},
   "source": [
    "## Q1 — What is Simple Linear Regression (SLR)?\n",
    "\n",
    "Simple Linear Regression models a relationship between a single predictor `x` and a target `y` using a line: $y = \\beta_0 + \\beta_1 x + \\epsilon$. It's used for prediction and to quantify association."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e8c55",
   "metadata": {},
   "source": [
    "## Q2 — Key assumptions of SLR\n",
    "\n",
    "Linearity, independence, homoscedasticity (constant variance), normality of errors (for inference), absence of influential outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee8e3a",
   "metadata": {},
   "source": [
    "## Q3 — Equation and terms\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 x + \\epsilon$ — where $\\beta_0$ is intercept, $\\beta_1$ slope, $\\epsilon$ noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d81716",
   "metadata": {},
   "source": [
    "## Q4 — Real-world example\n",
    "\n",
    "Predicting exam scores from hours studied; predicting house price from area (single predictor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fca167",
   "metadata": {},
   "source": [
    "## Q5 — Method of least squares\n",
    "\n",
    "Estimates coefficients by minimizing sum of squared residuals. Closed form for SLR: $\\hat{\\beta}_1 = \\frac{\\sum(x_i-\\bar x)(y_i-\\bar y)}{\\sum (x_i-\\bar x)^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20179358",
   "metadata": {},
   "source": [
    "## Q6 — Logistic vs Linear Regression\n",
    "\n",
    "Logistic is for classification (predicts probabilities via sigmoid), linear for continuous targets. Loss functions and outputs differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ca07f",
   "metadata": {},
   "source": [
    "## Q7 — Three common evaluation metrics\n",
    "\n",
    "- MSE, RMSE, MAE (definitions & brief use-cases)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21111a07",
   "metadata": {},
   "source": [
    "## Q8 — Purpose of R-squared\n",
    "\n",
    "Proportion of variance explained: $R^2 = 1 - \\frac{RSS}{TSS}$. Use adjusted R² when comparing models with different numbers of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb201e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned slope (beta1): 4.0528725673206285\n",
      "Learned intercept (beta0): 1.6720769260373993\n",
      "R^2 on training data: 0.94572\n",
      "MSE: 0.51621, RMSE: 0.71848, MAE: 0.56083\n",
      "\n",
      "Sample predictions:\n",
      "X=0.00 => predicted y=1.672076926037\n",
      "X=1.00 => predicted y=5.724949493358\n",
      "X=2.00 => predicted y=9.777822060679\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Recreate the synthetic data (seeded for reproducibility)\n",
    "rng = np.random.RandomState(42)\n",
    "X = 2.5 * rng.rand(100, 1)\n",
    "true_slope = 4.2\n",
    "true_intercept = 1.5\n",
    "noise = rng.normal(scale=0.8, size=(100, 1))\n",
    "y = true_intercept + true_slope * X + noise\n",
    "\n",
    "model = LinearRegression().fit(X, y.ravel())\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "preds = model.predict(X)\n",
    "r2 = r2_score(y, preds)\n",
    "mse = mean_squared_error(y, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y, preds)\n",
    "\n",
    "print(f\"Learned slope (beta1): {slope}\")\n",
    "print(f\"Learned intercept (beta0): {intercept}\")\n",
    "print(f\"R^2 on training data: {r2:.5f}\")\n",
    "print(f\"MSE: {mse:.5f}, RMSE: {rmse:.5f}, MAE: {mae:.5f}\")\n",
    "print('\\nSample predictions:')\n",
    "X_new = np.array([[0.0],[1.0],[2.0]])\n",
    "for xi, p in zip(X_new.ravel(), model.predict(X_new)):\n",
    "    print(f\"X={xi:.2f} => predicted y={p:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45084989",
   "metadata": {},
   "source": [
    "## Q10 — How to interpret coefficients\n",
    "\n",
    "- **Intercept (β0):** expected `y` when `x=0`.\n",
    "- **Slope (β1):** expected change in `y` for a one-unit increase in `x`.\n",
    "\n",
    "**Caveats:** association ≠ causation; consider confidence intervals and whether `x=0` is meaningful in your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fc0753",
   "metadata": {},
   "source": [
    "## How to run\n",
    "\n",
    "1. Open the notebook in Google Colab or Jupyter.\n",
    "2. Run all cells in order. The executed Q9 cell shows actual model outputs embedded.\n",
    "3. To reproduce, ensure scikit-learn and numpy are available (`pip install scikit-learn numpy`).\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook generated programmatically; contains no personal identifiers.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
