{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84cf38d",
   "metadata": {},
   "source": [
    "# Machine Learning â€“ KNN and PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a3516",
   "metadata": {},
   "source": [
    "## Q1: What is K-Nearest Neighbors (KNN)?\n",
    "\n",
    "KNN is a supervised learning algorithm that classifies or predicts values based on the majority class or average of the K closest data points in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8b79c",
   "metadata": {},
   "source": [
    "## Q2: Curse of Dimensionality\n",
    "\n",
    "As the number of dimensions increases, distances between data points become less meaningful, reducing KNN effectiveness and increasing computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1dbec",
   "metadata": {},
   "source": [
    "## Q3: What is PCA?\n",
    "\n",
    "PCA is a dimensionality reduction technique that transforms features into a smaller set of uncorrelated components while retaining most of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d645a16",
   "metadata": {},
   "source": [
    "## Q4: Eigenvalues and Eigenvectors in PCA\n",
    "\n",
    "Eigenvectors define principal component directions, while eigenvalues indicate the amount of variance captured by each component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac42fe",
   "metadata": {},
   "source": [
    "## Q5: How KNN and PCA work together\n",
    "\n",
    "PCA reduces dimensionality and noise, improving KNN performance and reducing computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 0.7777777777777778\n",
      "Accuracy with scaling: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Without scaling\n",
    "knn_raw = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_raw.fit(X_train, y_train)\n",
    "print(\"Accuracy without scaling:\", accuracy_score(y_test, knn_raw.predict(X_test)))\n",
    "\n",
    "# With scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_scaled.fit(X_train_scaled, y_train)\n",
    "print(\"Accuracy with scaling:\", accuracy_score(y_test, knn_scaled.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf2d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC1: 0.3574992453956305\n",
      "PC2: 0.19209250901858554\n",
      "PC3: 0.10845609661045434\n",
      "PC4: 0.07418330228706682\n",
      "PC5: 0.06935667393547071\n",
      "PC6: 0.05203091811029154\n",
      "PC7: 0.043914797205546266\n",
      "PC8: 0.025005533310710207\n",
      "PC9: 0.02202075119142149\n",
      "PC10: 0.019160301810529766\n",
      "PC11: 0.0165172341635893\n",
      "PC12: 0.012489177891226515\n",
      "PC13: 0.007273459069476921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "for i, var in enumerate(pca.explained_variance_ratio_):\n",
    "    print(f\"PC{i+1}: {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb3293f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with PCA (2 components): 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "pca_2 = PCA(n_components=2)\n",
    "X_train_pca = pca_2.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca_2.transform(X_test_scaled)\n",
    "\n",
    "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "print(\"Accuracy with PCA (2 components):\", accuracy_score(y_test, knn_pca.predict(X_test_pca)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae59484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean accuracy: 0.9333333333333333\n",
      "Manhattan accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "knn_euclidean = KNeighborsClassifier(metric=\"euclidean\")\n",
    "knn_manhattan = KNeighborsClassifier(metric=\"manhattan\")\n",
    "\n",
    "knn_euclidean.fit(X_train_scaled, y_train)\n",
    "knn_manhattan.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Euclidean accuracy:\", accuracy_score(y_test, knn_euclidean.predict(X_test_scaled)))\n",
    "print(\"Manhattan accuracy:\", accuracy_score(y_test, knn_manhattan.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82d910",
   "metadata": {},
   "source": [
    "## Q10: High-dimensional biomedical data solution\n",
    "\n",
    "PCA reduces dimensionality by retaining components that explain most variance (e.g., 95%). KNN is then applied on the reduced space. Model performance is evaluated using cross-validation, accuracy, precision, recall, and ROC-AUC. This pipeline reduces overfitting, improves efficiency, and is suitable for real-world biomedical datasets."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
